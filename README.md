# ğŸ“˜ Project README  

---

## ğŸ” Project Overview  
This project explores the design and development of **machine learning and accessibility-focused applications** that address real-world problems in education, accessibility, healthcare, and safety.  

The main focus of our group was the **Braille Text-to-Audio Translator**, an innovative solution aimed at enhancing accessibility for individuals with visual impairments by automatically detecting and translating Braille characters into audio in real time.  

---

## ğŸ’¡ Applications Proposed  

### 1ï¸âƒ£ System of Recommendations for Education  
An application designed to recommend study paths for students based on their interests.  

---

### 2ï¸âƒ£ Braille Text-to-Audio Translator *(Chosen Project)*  
- **Target**: Recognize and read Grade 1 Braille from images.  
- **Machine Learning Approach**: Supervised Learning â€“ Multi-class Classification using **CNN with ReLU and Softmax**.  
- **Dataset**: [Kaggle â€“ Braille Character Dataset](https://www.kaggle.com/datasets/shanks0465/braille-character-dataset?select=Dataset+Description.txt).  
- **Goal**: Extend to Grade 2 Braille (78 classes: 29 Grade 1 + 49 Grade 2).  
- **Similar Product**: [Braille Recognition iOS App](https://apps.apple.com/us/app/braille-recognition/id1669110413).  

---

### 3ï¸âƒ£ Colour Distinguisher  
An application designed to help individuals with **colour vision deficiency** distinguish between different colours.  
- Reference: [Color Inspector App](https://appadvice.com/app/color-inspector/645516384).  

---

### 4ï¸âƒ£ Prediction of Natural Disasters  
An application designed to **predict wildfires**, targeting suburban populations at risk.  

---

## ğŸ‘¥ Team Roles  
- **Coordinator**: Muhammad Fahad Sohail  
- **Facilitator**: Kwonmin Bok  
- **Notetaker**: Oyinkansola Ajibola  
- **Timekeeper**: Jianhui Qi  

---

## ğŸ¯ Why Braille Text-to-Audio Translator?  
Braille remains vital for individuals with visual impairments, but traditional methods (touch-based reading or audio books) present challenges in real-world scenarios.  

Our solution leverages **smartphone cameras** and envisions future integration into **smart glasses**, enabling:  
- âœ… Real-time Braille detection and audio translation.  
- âœ… Hands-free accessibility without physical contact (post-COVID safety).  
- âœ… Usability in noisy or complex environments.  

---

## âš™ï¸ Practicality  
- **Target Audience**: English Grade 1 Braille users (with scalability to Grade 2).  
- **Feasibility**: Public datasets (Kaggle) and libraries (TensorFlow, Keras).  
- **Timeline**: Completion expected in a few months with iterative training and testing.  

---

## ğŸ” Similar Products  
- Existing apps (e.g., *Braille Scanner*) require multiple steps for translation.  
- Our solution emphasizes **auto-detection** and **streamlined translation**, ensuring ease of use with minimal user interaction.  

---

## ğŸ§  Data & Model  
- **Input**: 28Ã—28 pixel images of Braille characters.  
- **Output**: Corresponding English alphabet audio.  
- **Technique**: **Convolutional Neural Network (CNN)** with ReLU (hidden layers) and Softmax (output layer).  

**Justification**:  
1. CNN reduces dimensionality while retaining essential features.  
2. Multi-class classification handles multiple Braille characters effectively.  
3. Softmax ensures probabilistic accuracy in classification.  

---

## âš ï¸ Limitations  
- Variability in captured Braille images (distortion, lighting, angles) may affect recognition accuracy.  

---

## ğŸ”„ Alternatives Considered  
- **Linear Regression** â†’ Not suitable for classification tasks.  
- **Perceptron** â†’ Limited to binary outputs, unsuitable for multi-class Braille recognition.  
- **Decision Tree** â†’ Too simplistic for handling complex Braille dot patterns.  

---

## ğŸš€ Key Takeaways  
- Applied **supervised learning** for accessibility innovation.  
- Explored **dataset preprocessing, CNN implementation, and real-world challenges**.  
- Focused on **usability, inclusivity, and scalability** for future assistive technologies.  

---

## ğŸ› ï¸ Tech Stack  
- ğŸ Python  
- ğŸ”· TensorFlow  
- ğŸ“Š Keras  
- ğŸ“· OpenCV  
- ğŸ§® NumPy & Pandas  

---

âœ¨ **Resume Highlight**  
*â€œDeveloped a machine learning-based Braille Text-to-Audio Translator leveraging CNNs and Kaggle datasets to enhance accessibility for visually impaired individuals. Designed for real-time detection and translation, with scalability to Grade 2 Braille. Collaborated in a structured team environment, handling dataset preprocessing, model design, and evaluation.â€*  
