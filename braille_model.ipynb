{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 4404 Group Project\n",
    "## Author: Oyinkansola Ajibola, Jianhui Qi, Muhammad Fahad Sohail, Kwonmin Bok\n",
    "\n",
    "**Original Dataset Source: Shanks0465. (2019). <i>Braille Character Dataset</i> [Data set]. Kaggle. https://www.kaggle.com/datasets/shanks0465/braille-character-dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Braille Character Dataset Description  \n",
    "This dataset was created for the purpose of training a CNN for Braille Character Recognition.\n",
    "\n",
    "**Image Description:**  \n",
    "Each image is a 28x28 image in Black and White Scale.\n",
    "Each image name consists of the character alphabet and the number of the image and the type of data augmentation it went through.\n",
    "(i.e whs - width height shift, rot - Rotation, dim - brightness)\n",
    "\n",
    "**Dataset composition:**  \n",
    "26 characters * 3 Augmentations * 20 different images of different augmentation values\n",
    "(i.e different shift,rotational and brightness values.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Look at the big picture and frame the problem.\n",
    "\n",
    "## Frame the problem\n",
    "1. Supervised learning\n",
    "2. A multi-class classification task\n",
    "3. Batch learning\n",
    "\n",
    "## Look at the big picture\n",
    "Predict the image and classify the braille character to english character.  \n",
    "It will help individuals with visual impairments to read the braille without physical touching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Load and Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 - Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pokkm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1326 files belonging to 26 classes.\n",
      "Found 234 files belonging to 26 classes.\n",
      "Found 234 files belonging to 26 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ds_train_bw_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pokkm\\Documents\\School\\EECS4404\\Projects\\EECS4404_Project\\braille_model.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m AUTOTUNE \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAUTOTUNE\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m ds_train \u001b[39m=\u001b[39m (\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     ds_train_\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m.\u001b[39mmap(convert_to_float)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39m.\u001b[39mcache()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mAUTOTUNE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m ds_valid_bw \u001b[39m=\u001b[39m (\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     ds_train_bw_\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m.\u001b[39mmap(convert_to_float)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m.\u001b[39mcache()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mAUTOTUNE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m ds_valid_col \u001b[39m=\u001b[39m (\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     ds_train_col_\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39m.\u001b[39mmap(convert_to_float)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39m.\u001b[39mcache()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mAUTOTUNE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pokkm/Documents/School/EECS4404/Projects/EECS4404_Project/braille_model.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ds_train_bw_' is not defined"
     ]
    }
   ],
   "source": [
    "# Set a dataset path and get all file paths\n",
    "# dataset_dir = Path(\"./dataset\")\n",
    "# file_list = list(dataset_dir.glob(\"*.jpg\"))\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    './dataset/train_bw_imgs/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=[28, 28],\n",
    "    interpolation='nearest',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "ds_valid_bw_ = image_dataset_from_directory(\n",
    "    './dataset/val_bw_imgs/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=[28, 28],\n",
    "    interpolation='nearest',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "ds_valid_col_ = image_dataset_from_directory(\n",
    "    './dataset/val_col_imgs/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=[28, 28],\n",
    "    interpolation='nearest',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_valid_bw = (\n",
    "    ds_valid_bw_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_valid_col = (\n",
    "    ds_valid_col_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create 2 arrays to store image inputs and labels\n",
    "# labels = []\n",
    "# images = []\n",
    "\n",
    "# # Read image file and store RGB values into the array\n",
    "# # Read the name of the image file and store its classifier\n",
    "# for file in file_list:\n",
    "#     image = cv2.imread(str(file))\n",
    "#     images.append(image)\n",
    "\n",
    "#     # Extract a file name of the image and transform the class to numeric value\n",
    "#     # Each file name of the image starts with its class\n",
    "#     # e.g.,) 'a1.JPG0dim.jpg' indicates the class of the image is 'a' and its numeric class is 0.\n",
    "#     #        Numeric classes are a = 0, b = 1, ... , and z = 25\n",
    "#     label = ord(os.path.basename(file)[0]) - ord('a')\n",
    "#     labels.append(label)\n",
    "\n",
    "# # Change the array to numpy array and normarlize RGB value to between 0 and 1\n",
    "# images = np.array(images) / 255.0\n",
    "# labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Take a quick look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To verify that the dataset is correctly transformed,\n",
    "# plot 48 images from the image datasets with the class name below each image\n",
    "# plt.figure(figsize = (8, 12))\n",
    "# for i in range(48):\n",
    "#     plt.subplot(8, 6, i + 1)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.grid(False)\n",
    "#     plt.imshow(images[i * 20])\n",
    "#     plt.xlabel(chr(labels[i * 20] + ord('a')))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Split dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% training set and 20% test set\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Create and test a CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Create a Convolutional Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filter=32, kernel_size=5, activation='relu', padding='same',\n",
    "                  input_shape=[28,28,3]),\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "    layers.Conv2D(filter=64, kernel_size=3, activation='relu', padding='same',),\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "    layers.Conv2D(filter=128, kernel_size=3, activation='relu', padding='same',),\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=520, activation='relu'),\n",
    "    layers.Dense(units=260, activation='softmax'),\n",
    "    layers.Dense(units=26, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
    "    loss='SparseCategoricalCrossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['train_accuracy', 'valid_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old model - Kaggle referenced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Convolutional Neural Network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Dropout(0.25),   \n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Dropout(0.25),   \n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    # To complete the model, we need to dense to 26 layers(number of classes) to perform classification.\n",
    "    # We need to flatten the layers first because the current output is a 3D tensor.\n",
    "    # And then, densing the layers upto 26 layers.\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=578, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(units=288, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=26, activation=\"softmax\") #output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"SparseCategoricalCrossentropy\", metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Set early stopping to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es1 = EarlyStopping(patience=20, monitor=\"val_sparse_categorical_accuracy\", mode=\"auto\")\n",
    "es2 = EarlyStopping(patience=20, monitor=\"val_loss\", mode=\"auto\")\n",
    "\n",
    "# Trainning will be stopped if it gets 20 epochs with no improvement\n",
    "history = model.fit(x=X_train,\n",
    "                    y=y_train,\n",
    "                    epochs=100,\n",
    "                    validation_split=0.3,\n",
    "                    callbacks=[es1, es2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Display summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Plot the history of loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(1, len(history.history['loss'])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=history.history, x=time, y='loss')\n",
    "sns.lineplot(data=history.history, x=time, y='val_loss')\n",
    "plt.title('Loss fitting history')\n",
    "plt.legend(labels=['Training Loss', 'Validation loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=history.history, x=time, y='val_sparse_categorical_accuracy')\n",
    "sns.lineplot(data=history.history, x=time, y='sparse_categorical_accuracy')\n",
    "plt.title('Accuracy fitting history')\n",
    "plt.legend(labels=['Training Accuracy', 'Valuation accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adam Optimizer\")\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Model - referenced by kaggle code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kag = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Dropout(0.25),   \n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Dropout(0.25),   \n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    keras.layers.Dense(units=576, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Dense(units=288, activation=\"relu\"),\n",
    "\n",
    "    keras.layers.Dense(units=26, activation=\"softmax\") #output layer\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
